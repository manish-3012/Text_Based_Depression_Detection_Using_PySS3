Hate me if you want but I'm trying to start a good discussion. America is as shitty a place to live as a lot of other places on the planet.  I mean sure we have more freedoms, but with that also comes more problems in a lot of places. Not saying we're not a good country. We're definitely not bad, but we're not great either.